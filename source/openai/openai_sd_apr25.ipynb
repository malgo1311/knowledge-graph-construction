{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36aef22-9d7d-44e9-9d19-1c44c6bec873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install openai\n",
    "# !rm /work/pi_dhruveshpate_umass_edu/project_19/aishwarya/696DS-named-entity-extraction-and-linking-for-KG-construction/code/openai/credentials.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99d5e11d-05fb-4046-b761-93ede66a80ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aa073b8-c238-4100-b18d-150340047184",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\"credentials.env\")\n",
    "api_key = os.getenv(\"api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "238bee08-9723-4dd1-b153-f97991355afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=api_key)\n",
    "model = \"gpt-4\" # gpt-3.5-turbo-instruct gpt-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db7b22-bb88-4736-b6dc-3115c3f3d070",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b6fc15a-631c-4016-9c33-870b28d0cda8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0227a118-e458-4721-88a4-3401eedcebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/work/pi_dhruveshpate_umass_edu/project_19/aishwarya/696DS-named-entity-extraction-and-linking-for-KG-construction/\"\n",
    "file = \"datasets/synthetic_data_Apr25/SD_Apr25_chunked_data.json\"\n",
    "\n",
    "with open(os.path.join(data_path, file), 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28b8a6fe-08eb-4f87-82dd-dda2d615f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(data), data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540bd782-d611-4367-9d86-7311caefa218",
   "metadata": {
    "tags": []
   },
   "source": [
    "### RElations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b13160-cc59-4085-b191-8a6612e7d537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>entity types</th>\n",
       "      <th>relationships</th>\n",
       "      <th>synthetic article</th>\n",
       "      <th>processed_entities</th>\n",
       "      <th>processed_relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62b1e91ce87f1fc6c056ce9172f5f7c66efba907</td>\n",
       "      <td>By . Lydia Warren . Jerry Sandusky's adopted s...</td>\n",
       "      <td>[['Jerry Sandusky', 'Person'], ['Matthew Sandu...</td>\n",
       "      <td>[['Matthew Sandusky', 'gave an interview to', ...</td>\n",
       "      <td>In a revealing and emotional interview with Op...</td>\n",
       "      <td>Jerry Sandusky; Matthew Sandusky; Oprah Winfre...</td>\n",
       "      <td>Matthew Sandusky | gave an interview to | Opra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ff693482cdd3dfb9e7064f487516b58f20c060ca</td>\n",
       "      <td>By . Jaymi Mccann . PUBLISHED: . 15:44 EST, 14...</td>\n",
       "      <td>[['Jaymi McCann', 'Person'], ['swimmer', 'Pers...</td>\n",
       "      <td>[['emergency services', 'conduct search and re...</td>\n",
       "      <td>In the scenic Brecon Beacons of Mid Wales, a s...</td>\n",
       "      <td>Jaymi McCann; swimmer; emergency services; pol...</td>\n",
       "      <td>emergency services | conduct search and rescue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>e9900c3b37b1ca3c0a62d203670f7e0e5ac5da89</td>\n",
       "      <td>By . Michael Zennie . A sightseer who tried to...</td>\n",
       "      <td>[['Michael Zennie', 'Person'], ['sightseer', '...</td>\n",
       "      <td>[['Grand Prismatic Spring', 'contains', 'bacte...</td>\n",
       "      <td>In the heart of Wyoming lies the Yellowstone N...</td>\n",
       "      <td>Michael Zennie; sightseer; Yellowstone; Grand ...</td>\n",
       "      <td>Grand Prismatic Spring | contains | bacteria\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>fe9d8a82cb4122fdd905012becc7418e2d2ff740</td>\n",
       "      <td>Facebook has started collecting information ab...</td>\n",
       "      <td>[['Facebook', 'Organization'], ['users', 'Conc...</td>\n",
       "      <td>[['Facebook', 'collects information from', 'us...</td>\n",
       "      <td>In a bold move that has stirred up the digital...</td>\n",
       "      <td>Facebook; users; social media site; privacy po...</td>\n",
       "      <td>Facebook | collects information from | users\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>aceee806bdda590589d85f67401e6a6a2fc46b2f</td>\n",
       "      <td>By . Deborah Arthurs . PUBLISHED: . 08:32 EST,...</td>\n",
       "      <td>[['Duchess of Cambridge', 'Person'], ['Hobbs',...</td>\n",
       "      <td>[['Duchess of Cambridge', 'wore clothing from'...</td>\n",
       "      <td>In a remarkable display of support for the Bri...</td>\n",
       "      <td>Duchess of Cambridge; Hobbs; Celeste coat; Liv...</td>\n",
       "      <td>Duchess of Cambridge | wore clothing from | Ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_key                                        id  \\\n",
       "0        0  62b1e91ce87f1fc6c056ce9172f5f7c66efba907   \n",
       "1        1  ff693482cdd3dfb9e7064f487516b58f20c060ca   \n",
       "2        2  e9900c3b37b1ca3c0a62d203670f7e0e5ac5da89   \n",
       "3        3  fe9d8a82cb4122fdd905012becc7418e2d2ff740   \n",
       "4        4  aceee806bdda590589d85f67401e6a6a2fc46b2f   \n",
       "\n",
       "                                             article  \\\n",
       "0  By . Lydia Warren . Jerry Sandusky's adopted s...   \n",
       "1  By . Jaymi Mccann . PUBLISHED: . 15:44 EST, 14...   \n",
       "2  By . Michael Zennie . A sightseer who tried to...   \n",
       "3  Facebook has started collecting information ab...   \n",
       "4  By . Deborah Arthurs . PUBLISHED: . 08:32 EST,...   \n",
       "\n",
       "                                        entity types  \\\n",
       "0  [['Jerry Sandusky', 'Person'], ['Matthew Sandu...   \n",
       "1  [['Jaymi McCann', 'Person'], ['swimmer', 'Pers...   \n",
       "2  [['Michael Zennie', 'Person'], ['sightseer', '...   \n",
       "3  [['Facebook', 'Organization'], ['users', 'Conc...   \n",
       "4  [['Duchess of Cambridge', 'Person'], ['Hobbs',...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  [['Matthew Sandusky', 'gave an interview to', ...   \n",
       "1  [['emergency services', 'conduct search and re...   \n",
       "2  [['Grand Prismatic Spring', 'contains', 'bacte...   \n",
       "3  [['Facebook', 'collects information from', 'us...   \n",
       "4  [['Duchess of Cambridge', 'wore clothing from'...   \n",
       "\n",
       "                                   synthetic article  \\\n",
       "0  In a revealing and emotional interview with Op...   \n",
       "1  In the scenic Brecon Beacons of Mid Wales, a s...   \n",
       "2  In the heart of Wyoming lies the Yellowstone N...   \n",
       "3  In a bold move that has stirred up the digital...   \n",
       "4  In a remarkable display of support for the Bri...   \n",
       "\n",
       "                                  processed_entities  \\\n",
       "0  Jerry Sandusky; Matthew Sandusky; Oprah Winfre...   \n",
       "1  Jaymi McCann; swimmer; emergency services; pol...   \n",
       "2  Michael Zennie; sightseer; Yellowstone; Grand ...   \n",
       "3  Facebook; users; social media site; privacy po...   \n",
       "4  Duchess of Cambridge; Hobbs; Celeste coat; Liv...   \n",
       "\n",
       "                                 processed_relations  \n",
       "0  Matthew Sandusky | gave an interview to | Opra...  \n",
       "1  emergency services | conduct search and rescue...  \n",
       "2  Grand Prismatic Spring | contains | bacteria\\n...  \n",
       "3  Facebook | collects information from | users\\n...  \n",
       "4  Duchess of Cambridge | wore clothing from | Ho...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# entities_data = pd.read_csv(os.path.join(data_path, \"datasets/synthetic_data_Apr25/news_training_processed.csv\"))\n",
    "entities_data = pd.read_csv(\"/work/pi_dhruveshpate_umass_edu/project_19/aishwarya/696DS-named-entity-extraction-and-linking-for-KG-construction/datasets/synthetic_data_Apr25/news_training_processed.csv\")\n",
    "entities_data = entities_data.rename(columns={\"Unnamed: 0\": 'doc_key'})\n",
    "\n",
    "print(entities_data.shape)\n",
    "entities_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "92d0a7c1-dac1-4ac7-a216-20507999dedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jerry Sandusky; Matthew Sandusky; Oprah Winfrey; OWN; Penn State; Dottie Sandusky; NBC; Sundance Film Festival; Pennsylvania; Tom Corbett; Victim 1'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_data[\"processed_entities\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2db11365-7e1c-4518-8f22-bd506c781d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>entities</th>\n",
       "      <th>latency</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "      <th>processed_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>All News Today; 2012/04/09; ABILA; Kronos; Sil...</td>\n",
       "      <td>1.462747</td>\n",
       "      <td>658</td>\n",
       "      <td>28</td>\n",
       "      <td>All News Today; 2012/04/09; ABILA; Kronos; Sil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    doc_key  chunk_index                                           entities  \\\n",
       "32        3            0  All News Today; 2012/04/09; ABILA; Kronos; Sil...   \n",
       "\n",
       "     latency  input_tokens  output_tokens  \\\n",
       "32  1.462747           658             28   \n",
       "\n",
       "                                   processed_entities  \n",
       "32  All News Today; 2012/04/09; ABILA; Kronos; Sil...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_data.loc[lambda df: df.doc_key == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cf34e87-f82e-49ab-b481-ce90d4b26db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = {}\n",
    "for idx in entities_data.index:\n",
    "    doc_key = entities_data[\"doc_key\"][idx]\n",
    "    data_json[doc_key] = entities_data[\"processed_entities\"][idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51d97b9e-a1ee-4e68-9adb-b14b1db5e3d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Facebook; users; social media site; privacy policy; advertisers; Facebook spokesman; cookies; web browser; device; Labour MP Helen Goodman; profits; advertising revenues; John Hemming; Liberal Democrat MP; Big Brother Watch; Renate Samson; chief executive; privacy campaign group; privacy settings; ad preferences tool; Amazon'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256edf00-a02c-4e3f-9837-fbd5bcbc88c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43cb8b5-596b-422b-b318-c5c782840e36",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Entities Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d21fa8f4-3009-47d2-9d84-abfd8a27241e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/work/pi_dhruveshpate_umass_edu/project_19/ReDocREDPreprocessing/Re-DocRED/processed/\"\n",
    "file_v2 = \"Re-DocRED_Processed_Train.csv\"\n",
    "    \n",
    "def get_entity_example(idx, datatmp):\n",
    "    allEntities = set()\n",
    "    for item in datatmp[\"Triplets\"][idx].split(\"\\n\"):\n",
    "        item = item.split(\" | \")\n",
    "        if len(item) == 3:\n",
    "            allEntities.add(item[0])\n",
    "            allEntities.add(item[2])\n",
    "\n",
    "    return datatmp[\"Text\"][idx], '; '.join(list(allEntities))\n",
    "    \n",
    "def get_entities_prompt(text):\n",
    "    \n",
    "    data_v2 = pd.read_csv(os.path.join(data_path, file_v2), skiprows = range(1, 2000), nrows = 500)\n",
    "    \n",
    "    ex1, exout1 = get_entity_example(1, data_v2)\n",
    "    ex2, exout2 = get_entity_example(2, data_v2)\n",
    "\n",
    "    prompt=f'''Task: Please detect all the entities from the given input Text.\n",
    "Entities could be people, organization, places, concepts, dates or any other proper nouns present in the text. \\\n",
    "Use the following examples as reference to understand the task. \\\n",
    "Give the output in the same format as given in the Example Entities Output, i.e., separated by a semicolon, ';'.\n",
    "\n",
    "Example Text 1: {ex1}\n",
    "Example Entities Output 1: {exout1}\n",
    "\n",
    "Example Text 2: {ex2}\n",
    "Example Entities Output 2: {exout2}\n",
    "\n",
    "Text: {text}\n",
    "Entities Output:'''\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def get_system_msg():\n",
    "    \n",
    "    data_v2 = pd.read_csv(os.path.join(data_path, file_v2), skiprows = range(1, 2000), nrows = 500)\n",
    "    \n",
    "    ex1, exout1 = get_entity_example(1, data_v2)\n",
    "    ex2, exout2 = get_entity_example(2, data_v2)\n",
    "\n",
    "    prompt=f'''You are a helpful assistant and an expert in named entity extraction.\n",
    "Task: Please detect all the entities from the given input Text.\n",
    "Entities could be people, organization, places, concepts, dates or any other proper nouns present in the text. \\\n",
    "Use the following examples as reference to understand the task. \\\n",
    "Give the output in the same format as given in the Example Entities Output, i.e., separated by a semicolon, ';'.\n",
    "\n",
    "Example Text 1: {ex1}\n",
    "Example Entities Output 1: {exout1}\n",
    "\n",
    "Example Text 2: {ex2}\n",
    "Example Entities Output 2: {exout2}'''\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "def get_content(text):\n",
    "    \n",
    "    prompt=f'''Text: {text}\n",
    "Entities Output:'''\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ee0a58-a03d-45ca-958d-4a614c318d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant and an expert in named entity extraction.\n",
      "Task: Please detect all the entities from the given input Text.\n",
      "Entities could be people, organization, places, concepts, dates or any other proper nouns present in the text. Use the following examples as reference to understand the task. Give the output in the same format as given in the Example Entities Output, i.e., separated by a semicolon, ';'.\n",
      "\n",
      "Example Text 1: Udawalawe National Park lies on the boundary of Sabaragamuwa and Uva Provinces, in Sri Lanka. The national park was created to provide a sanctuary for wild animals displaced by the construction of the Udawalawe Reservoir on the Walawe River, as well as to protect the catchment of the reservoir. The reserve covers of land area and was established on 30 June 1972. Before the designation of the national park, the area was used for shifting cultivation (chena farming). The farmers were gradually removed once the national park was declared. The park is from Colombo. Udawalawe is an important habitat for water birds and Sri Lankan elephants. It is a popular tourist destination and the third most visited park in the country. \n",
      "Example Entities Output 1: Udawalawe Reservoir; 30 June 1972; Colombo; Sri Lanka; Walawe River; Sabaragamuwa; Udawalawe National Park; Uva Provinces\n",
      "\n",
      "Example Text 2: The Road to Ruin is a 1970 album released by husband and wife John and Beverley Martyn. It was the second (and last) album released as a duo. Island Records persuaded John Martyn to resume his solo career as they believed that the public was more interested in John as a solo artist rather than as part of a duo. The album marked the first collaboration on record between John and bassist Danny Thompson, who featured on many of Martyn's subsequent recordings. The album's first track \" Primrose Hill \" written and sung by Beverley Martyn, and featuring Ray Warleigh on saxophone, about the simple joys of domesticity, was extensively sampled by Fatboy Slim for the track \" North West Three \" from his 2004 album Palookaville. \n",
      "Example Entities Output 2: Beverley Martyn; Danny Thompson; The Road to Ruin; 1970; Palookaville; Island Records; Martyn; 2004; Fatboy Slim; Primrose Hill; John; Road to Ruin\n",
      "Text: hey\n",
      "Entities Output:\n"
     ]
    }
   ],
   "source": [
    "print(get_system_msg())\n",
    "print(get_content(\"hey\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7a13b8-f380-49da-9f9d-a0949eeefd15",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Relations Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f545d243-8478-4867-8d0c-0fc48d530cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/work/pi_dhruveshpate_umass_edu/project_19/ReDocREDPreprocessing/Re-DocRED/processed/\"\n",
    "file_v2 = \"Re-DocRED_Processed_Train.csv\"\n",
    "    \n",
    "def get_example(idx, datatmp):\n",
    "    allEntities = set()\n",
    "    for item in datatmp[\"Triplets\"][idx].split(\"\\n\"):\n",
    "        item = item.split(\" | \")\n",
    "        # print(item, len(item))\n",
    "        if len(item) == 3:\n",
    "            allEntities.add(item[0])\n",
    "            allEntities.add(item[2])\n",
    "\n",
    "    allEntities = list(allEntities)\n",
    "    # print(allEntities)\n",
    "    # return datatmp[\"Text\"][idx], allEntities, datatmp[\"Triplets\"][idx]\n",
    "    return datatmp[\"Text\"][idx], \"; \".join(allEntities), datatmp[\"Triplets\"][idx]\n",
    "    \n",
    "def get_relations_prompt(text, entities):\n",
    "    \n",
    "    data_v2 = pd.read_csv(os.path.join(data_path, file_v2), skiprows = range(1, 2000), nrows = 500)\n",
    "    \n",
    "    ex1, exent1, exout1 = get_example(1, data_v2)\n",
    "    ex2, exent2, exout2 = get_example(2, data_v2)\n",
    "\n",
    "    prompt=f'''Task Description:\n",
    "The task is to extract Relations between the Entity List for given text, in the form of triplets. \\\n",
    "Extract triplets from the given Text based solely on the relationships present in the text. \\\n",
    "Ensure that entities are chosen directly from the provided Entity List to maintain accuracy. \\\n",
    "Avoid duplicating triplets in the output. Use the provided Example Text and Relations Output as references \\\n",
    "to understand how to identify meaningful relationships between entities from Entity List. \\\n",
    "Pay attention to all potential relations between all the entities and include them in the output.\n",
    "\n",
    "Example Text 1: {ex1}\n",
    "Entity List of Text 1: {exent1}\n",
    "Relations Output of Text 1: {exout1}\n",
    "\n",
    "Example Text 2: {ex2}\n",
    "Entity List of Text 2: {exent2}\n",
    "Relations Output of Text 2: {exout2}\n",
    "\n",
    "Text: {text}\n",
    "Entity List: {entities}\n",
    "Relations Output:'''\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e16651c-52a6-468d-b318-0391b6548ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Description:\n",
      "The task is to extract Relations between the Entity List for given text, in the form of triplets. Extract triplets from the given Text based solely on the relationships present in the text. Ensure that entities are chosen directly from the provided Entity List to maintain accuracy. Avoid duplicating triplets in the output. Use the provided Example Text and Relations Output as references to understand how to identify meaningful relationships between entities from Entity List. Pay attention to all potential relations between all the entities and include them in the output.\n",
      "\n",
      "Example Text 1: Udawalawe National Park lies on the boundary of Sabaragamuwa and Uva Provinces, in Sri Lanka. The national park was created to provide a sanctuary for wild animals displaced by the construction of the Udawalawe Reservoir on the Walawe River, as well as to protect the catchment of the reservoir. The reserve covers of land area and was established on 30 June 1972. Before the designation of the national park, the area was used for shifting cultivation (chena farming). The farmers were gradually removed once the national park was declared. The park is from Colombo. Udawalawe is an important habitat for water birds and Sri Lankan elephants. It is a popular tourist destination and the third most visited park in the country. \n",
      "Entity List of Text 1: Walawe River; Sri Lanka; 30 June 1972; Uva Provinces; Udawalawe Reservoir; Colombo; Udawalawe National Park; Sabaragamuwa\n",
      "Relations Output of Text 1: Sabaragamuwa | located in the administrative territorial entity | Sri Lanka\n",
      "Sabaragamuwa | country | Sri Lanka\n",
      "Sri Lanka | contains administrative territorial entity | Sabaragamuwa\n",
      "Sri Lanka | contains administrative territorial entity | Uva Provinces\n",
      "Walawe River | country | Sri Lanka\n",
      "Udawalawe National Park | located in the administrative territorial entity | Sabaragamuwa\n",
      "Udawalawe National Park | country | Sri Lanka\n",
      "Udawalawe National Park | inception | 30 June 1972\n",
      "Colombo | country | Sri Lanka\n",
      "Udawalawe Reservoir | country | Sri Lanka\n",
      "Uva Provinces | country | Sri Lanka\n",
      "Uva Provinces | located in the administrative territorial entity | Sri Lanka\n",
      "Walawe River | located in the administrative territorial entity | Sri Lanka\n",
      "Udawalawe National Park | located in the administrative territorial entity | Sri Lanka\n",
      "Colombo | located in the administrative territorial entity | Sri Lanka\n",
      "Udawalawe Reservoir | located in the administrative territorial entity | Sri Lanka\n",
      "\n",
      "\n",
      "Example Text 2: The Road to Ruin is a 1970 album released by husband and wife John and Beverley Martyn. It was the second (and last) album released as a duo. Island Records persuaded John Martyn to resume his solo career as they believed that the public was more interested in John as a solo artist rather than as part of a duo. The album marked the first collaboration on record between John and bassist Danny Thompson, who featured on many of Martyn's subsequent recordings. The album's first track \" Primrose Hill \" written and sung by Beverley Martyn, and featuring Ray Warleigh on saxophone, about the simple joys of domesticity, was extensively sampled by Fatboy Slim for the track \" North West Three \" from his 2004 album Palookaville. \n",
      "Entity List of Text 2: Palookaville; 2004; Beverley Martyn; Martyn; 1970; John; Fatboy Slim; Island Records; Road to Ruin; Danny Thompson; Primrose Hill; The Road to Ruin\n",
      "Relations Output of Text 2: John | record label | Island Records\n",
      "John | spouse | Beverley Martyn\n",
      "Beverley Martyn | spouse | John\n",
      "Beverley Martyn | record label | Island Records\n",
      "Beverley Martyn | spouse | Martyn\n",
      "Road to Ruin | publication date | 1970\n",
      "Road to Ruin | record label | Island Records\n",
      "Martyn | record label | Island Records\n",
      "Palookaville | publication date | 2004\n",
      "Palookaville | performer | Fatboy Slim\n",
      "Primrose Hill | performer | Beverley Martyn\n",
      "Primrose Hill | part of | The Road to Ruin\n",
      "The Road to Ruin | publication date | 1970\n",
      "Primrose Hill | publication date | 1970\n",
      "The Road to Ruin | performer | Martyn\n",
      "Danny Thompson | record label | Island Records\n",
      "Primrose Hill | record label | Island Records\n",
      "Road to Ruin | performer | John\n",
      "The Road to Ruin | performer | John\n",
      "The Road to Ruin | record label | Island Records\n",
      "Martyn | spouse | Beverley Martyn\n",
      "Fatboy Slim | notable work | Palookaville\n",
      "Beverley Martyn | notable work | Primrose Hill\n",
      "The Road to Ruin | has part | Primrose Hill\n",
      "Martyn | notable work | The Road to Ruin\n",
      "John | notable work | Road to Ruin\n",
      "John | notable work | The Road to Ruin\n",
      "\n",
      "\n",
      "Text: text\n",
      "Entity List: entities\n",
      "Relations Output:\n"
     ]
    }
   ],
   "source": [
    "print(get_relations_prompt(data['0']['chunk_text'], \"entities\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9641eefd-8124-4300-b6ac-54155a5196cc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'chunk_index': 0, 'chunk_text': \"In a revealing and emotional interview with Oprah Winfrey, Matthew Sandusky, the adopted son of convicted pedophile Jerry Sandusky, shared his harrowing experience of abuse on the OWN network.\\n\\nThe exclusive conversation, which aired on Thursday night, marked Matthew's first television appearance since the trial that led to his father's conviction in 2012.\\n\\nMatthew Sandusky, who was one of six children adopted by Jerry and Dottie Sandusky, recounted the years of sexual abuse he suffered from the age of eight to fifteen.\\n\\nHe described a chilling nightly ritual where his father would enter his bedroom and molest him, leaving him to cower in a fetal position in a desperate attempt to avoid the abuse.\\n\\nHis story first came to light when a secret tape of his interview with the police, conducted during his father's trial, was leaked to NBC, sending shockwaves through the community.\", 'chunk_tokens': 163}, {'chunk_index': 1, 'chunk_text': \"Jerry Sandusky, the former Penn State defensive coordinator, was convicted of molesting 10 boys over a span of 15 years, some incidents occurring in the football team's showers on campus.\\n\\nThe 70-year-old is now serving a 30- to 60-year state prison sentence.\\n\\nThe case against him was a major scandal for Penn State, leading to a settlement with Matthew last year.\\n\\nIn the aftermath, Matthew petitioned to legally change his name, as well as those of his wife and four children, in an effort to distance himself from the Sandusky legacy.\\n\\nThe interview with Oprah Winfrey on OWN delved into Matthew's feelings of betrayal by his adoptive mother, Dottie Sandusky, who publicly accused him of lying and stealing from the family.\\n\\nDespite the accusations and the lack of support from his adoptive parents, Matthew stood firm in his decision to speak out against the man who had adopted him from a deprived upbringing and brought him up in an affluent household.\", 'chunk_tokens': 179}, {'chunk_index': 2, 'chunk_text': \"Matthew's courage to share his story was also highlighted in a documentary at the Sundance Film Festival in January, where he expressed his sense of betrayal by the entire Sandusky family.\\n\\nHis decision to come forward was a brave stand against those who had once provided him with a home and a seemingly better life.\\n\\nThe Sandusky case was further scrutinized when Pennsylvania's attorney general released a review of the prosecution, revealing three years of 'inexplicable delays' in prosecuting the former Penn State coach on child abuse charges.\\n\\nThe report found no evidence of political interference by then-Governor Tom Corbett, but it did note that the pedophile's home was not searched promptly and that it took over a year for the office to recommend charging Sandusky after 'Victim 1' came forward.\\n\\nThe arrest was delayed for more than 18 months as the prosecutor's supervisors believed the testimony of one victim would be insufficient against a community icon like Sandusky.\", 'chunk_tokens': 173}, {'chunk_index': 3, 'chunk_text': 'The Sandusky scandal has left an indelible mark on the Penn State community and the state of Pennsylvania.\\n\\nIt has raised questions about the responsibilities of institutions and the lengths to which they will go to protect their reputation.\\n\\nThe case has also highlighted the importance of listening to and supporting victims of abuse, no matter the stature of the accused.\\n\\nAs Matthew Sandusky continues to heal from his past and advocate for other victims of abuse, his story serves as a powerful reminder of the resilience of the human spirit in the face of unimaginable adversity.\\n\\nHis interview with Oprah Winfrey on OWN has given a voice to the silent suffering of many and has shed light on the dark corners of abuse that often go unnoticed.', 'chunk_tokens': 135}, {'chunk_index': 4, 'chunk_text': \"The courage of Matthew and 'Victim 1', along with the other victims who came forward, has helped to ensure that justice was served, and that the legacy of Jerry Sandusky will forever be one of infamy rather than accolades in the halls of Penn State and beyond.\", 'chunk_tokens': 52}]\n"
     ]
    }
   ],
   "source": [
    "for item in data:\n",
    "    print(data['0']['chunk_text'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3615c7f-aef2-464a-aef1-61a33b34afc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the scenic Brecon Beacons of Mid Wales, a serene yet tragic scene unfolded at the Cantref Reservoir.\\n\\nThe emergency services, including local police, were engaged in a large-scale search and rescue operation.\\n\\nA young swimmer, believed to be a local from Merthyr Tydfil in South Wales, had vanished beneath the waters of the reservoir, sparking fears and a desperate search.\\n\\nThe Cantref Reservoir, a popular spot during the sweltering summer months, had attracted hundreds of visitors seeking respite from the heatwave that gripped the nation.\\n\\nThe police had been issuing stern warnings about the dangers of swimming in unmanned waters, emphasizing the risks associated with such activities during the heatwave.\\n\\nDespite these warnings, the young man, in his 20s, had taken a leap into the cool depths to escape the relentless heat, only to disappear.\\n\\nAs the search continued, the police utilized boats and helicopters to scour the miles of water surrounding the reservoir.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['1'][0]['chunk_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "559f56ed-4a1a-48ea-8304-c7be0446cf4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jaymi McCann; swimmer; emergency services; police; Cantref Reservoir; Brecon Beacons; Mid Wales; Merthyr Tydfil; South Wales; Met Office; health authorities; elderly people; Level 2 alerts'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities_data[\"processed_entities\"][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ad580a-807f-4ec1-8622-4997755e9d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_entities_prompt(\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395e85e4-52d8-419a-8f73-f6aa27572d6b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae783b55-07a1-4d5f-bc02-9057939342d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(text):\n",
    "    \n",
    "    prompt = get_entities_prompt(text)\n",
    "    \n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature = 0,\n",
    "        max_tokens = 256,\n",
    "    )\n",
    "    time_diff = time.time() - start\n",
    "    \n",
    "    return response, time_diff\n",
    "\n",
    "def get_chat_prediction(messages):\n",
    "    \n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature = 0,\n",
    "        max_tokens = 256,\n",
    "    )\n",
    "    time_diff = time.time() - start\n",
    "    \n",
    "    return response, time_diff\n",
    "\n",
    "\n",
    "def get_relation_prediction(text, entities):\n",
    "    \n",
    "    prompt = get_relations_prompt(text, entities)\n",
    "    \n",
    "    start = time.time()\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        temperature=0,\n",
    "    )\n",
    "    time_diff = time.time() - start\n",
    "    \n",
    "    return response, time_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec205d4-b5d4-42c2-ad7c-91afe5ca81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data = []\n",
    "output_filename = \"sdapr25_entities.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f41e37d-c082-473e-a297-2abb86400741",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Entity Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "679fb154-3ab1-4806-870b-de37e6e11ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/924 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input - In a recent development that has sparked both interest and controversy, Mothers Against Drunk Driving (MADD), a prominent anti-drink driving group, has released a glowing report on Uber, the widely-used ride-sharing service.\n",
      "\n",
      "The report, which was jointly published with Uber, suggests that the availability of transportation options like Uber has contributed to a reduction in drink-driving accidents across America's cities.\n",
      "\n",
      "The study has come under the spotlight after it was revealed that Uber started donating money to MADD last summer, raising questions about the potential influence of financial relationships on research outcomes.\n",
      "\n",
      "Despite the scrutiny, MADD, backed by its senior vice president of marketing and communications, Amy George, is not backing away from the report's findings.\n",
      "\n",
      "output - Mothers Against Drunk Driving; MADD; Uber; America; Amy George\n",
      "\n",
      "Input - Amy George has been actively communicating with media outlets such as Pro Publica and Valley Wag, emphasizing that the data presented in the study is correlative and shows that Uber is having a significant impact on reducing drunk-driving incidents.\n",
      "\n",
      "Uber's involvement with MADD goes beyond just the report.\n",
      "\n",
      "The two entities announced a partnership last year, where Uber pledged to donate $1 for every ride taken and $10 for every new customer who used the service during a 24-hour period around the 4th of July, provided customers used the promo code UberMADD.\n",
      "\n",
      "A similar initiative was launched on Super Bowl Sunday, with Uber donating $1 for every passenger who used the code ThinkandRide between 3 pm and midnight.\n",
      "\n",
      "The report's findings are particularly noteworthy in California, Uber's home state, where drunk-driving crashes among drivers under 30 have fallen by 6.5 percent in markets where Uber operates.\n",
      "\n",
      "This equates to an estimated 1,800 crashes prevented since July 2012.\n",
      "\n",
      "output - Amy George; Pro Publica; Valley Wag; Uber; MADD; 4th of July; UberMADD; Super Bowl Sunday; ThinkandRide; 3 pm; midnight; California; 6.5 percent; July 2012\n",
      "\n",
      "Input - This equates to an estimated 1,800 crashes prevented since July 2012.\n",
      "\n",
      "The company claims that this drop is indicative of a possible similar reduction in other markets where Uber is available.\n",
      "\n",
      "Critics, however, caution against hastily drawing causal connections from the report.\n",
      "\n",
      "Amy George has clarified that the figures indicating a drop in drink-driving in cities where Uber is used are purely correlational.\n",
      "\n",
      "\"Nobody is saying that there is a causation relationship here,\" she told Pro Publica.\n",
      "\n",
      "Despite this, she denied distancing herself from the study and stated that MADD strongly stands behind the report and continues to support its findings.\n",
      "\n",
      "The research, which has been a collaborative effort between MADD and Uber, indicates that when people are empowered with more transportation options, they tend to make safer choices.\n",
      "\n",
      "This assertion is supported by the data in the report, which has been validated by the research team's rigorous analysis.\n",
      "\n",
      "output - Amy George; July 2012; Uber; Pro Publica; MADD\n",
      "\n",
      "Input - The financial relationship between Uber and MADD has been transparent, with Uber making donations to the organization.\n",
      "\n",
      "However, the exact amount of money passed to MADD has not been disclosed.\n",
      "\n",
      "This relationship has led to some skepticism about the objectivity of the report, but both organizations maintain that the study's conclusions are valid and stand on their own merit.\n",
      "\n",
      "In light of the report, there is a growing conversation about the role of ride-sharing services in public safety and their potential to reduce the incidence of drunk-driving crashes.\n",
      "\n",
      "The study's emphasis on the impact of transportation options like Uber on safety and the reduction of crashes has brought attention to the need for more accessible and responsible transportation solutions.\n",
      "\n",
      "As the debate continues, MADD and Uber remain steadfast in their partnership and their commitment to combating drink-driving.\n",
      "\n",
      "output - Uber; MADD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 5/924 [00:10<31:22,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input - With the report's findings being a topic of discussion among policymakers, researchers, and the public, the conversation about the relationship between ride-sharing services and road safety is far from over.\n",
      "\n",
      "The ongoing dialogue underscores the importance of examining the correlations between data and real-world outcomes, as well as the need for transparency in financial relationships between organizations and their research partners.\n",
      "\n",
      "output - ride-sharing services; road safety; policymakers; researchers; financial relationships; organizations; research partners\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "debug = True\n",
    "\n",
    "all_keys = list(data.keys())\n",
    "\n",
    "for i in tqdm(range(len(all_keys))):\n",
    "    \n",
    "    doc_key = all_keys[i]\n",
    "    \n",
    "    if doc_key != '5' and debug:\n",
    "        continue\n",
    "    \n",
    "    # messages = [{\"role\": \"system\", \"content\": get_system_msg()}]\n",
    "    \n",
    "    for item in data[doc_key]:\n",
    "        \n",
    "        # print(messages)\n",
    "    \n",
    "        #\n",
    "        text = item['chunk_text']\n",
    "        chunk_idx = item['chunk_index']\n",
    "        \n",
    "        # messages.append({\"role\": \"user\", \"content\": get_content(text)})\n",
    "        \n",
    "        output, time_diff = get_prediction(text)\n",
    "        # output, time_diff = get_chat_prediction(messages)\n",
    "        # output, time_diff = get_relation_prediction(i)\n",
    "\n",
    "        outputText = output.choices[0].message.content\n",
    "        input_tokens = output.usage.prompt_tokens\n",
    "        output_tokens = output.usage.completion_tokens\n",
    "        \n",
    "        # messages.append({\"role\": \"assistant\", \"content\": outputText})\n",
    "\n",
    "        if debug:\n",
    "            print(f\"\\nInput - {text}\")\n",
    "            # print(f\"\\nGT - {data['Triplets'][i]}\")\n",
    "            print(f\"\\noutput - {outputText}\")\n",
    "\n",
    "        output_data.append([doc_key, chunk_idx, outputText, time_diff,\n",
    "                           input_tokens, output_tokens])\n",
    "\n",
    "        if i % 10 == 0 and i > 1:\n",
    "\n",
    "            with open(output_filename, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(output_data)\n",
    "                \n",
    "        # if debug: break\n",
    "        \n",
    "    if debug: break\n",
    "    \n",
    "    with open(output_filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21755fa2-fff9-4927-8fa1-2ff95441c619",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Relation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5356e2cb-78bc-4862-ac6e-1b117fca526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "292579ae-7486-403a-933a-184cc147fda6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('0', 0), ('0', 1), ('0', 2), ('0', 3), ('0', 4), ('0', 5)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bbe4f2f-a3ef-4ac4-83b6-853b71441b0e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 847/847 [00:06<00:00, 128.34it/s]\n"
     ]
    }
   ],
   "source": [
    "debug = True\n",
    "\n",
    "all_keys = list(data.keys())\n",
    "\n",
    "for i in tqdm(range(len(all_keys))):\n",
    "    \n",
    "    doc_key = all_keys[i]\n",
    "    \n",
    "    # if doc_key != '3' and debug:\n",
    "    #     continue\n",
    "        \n",
    "    # if doc_key != '400':\n",
    "    #     continue\n",
    "    \n",
    "    # messages = [{\"role\": \"system\", \"content\": get_system_msg()}]\n",
    "    \n",
    "    for item in data[doc_key]:\n",
    "        \n",
    "        # print(doc_key, item)\n",
    "        \n",
    "        # print(messages)\n",
    "    \n",
    "        #\n",
    "        text = item['chunk_text']\n",
    "        chunk_idx = item['chunk_index']\n",
    "        \n",
    "        # print(doc_key, chunk_idx)\n",
    "        \n",
    "        \n",
    "        # if (doc_key, chunk_idx) != ('3',0):\n",
    "        #     continue\n",
    "            \n",
    "        # if (doc_key, chunk_idx) in processed:\n",
    "        #     continue\n",
    "        # else:\n",
    "        #     processed.add((doc_key, chunk_idx))\n",
    "        \n",
    "        # if int(chunk_index) in data_json[int(doc_key)]:\n",
    "        processed_entities = data_json[int(doc_key)][chunk_idx]\n",
    "\n",
    "        # messages.append({\"role\": \"user\", \"content\": get_content(text)})\n",
    "\n",
    "        # output, time_diff = get_prediction(text)\n",
    "        # output, time_diff = get_chat_prediction(messages)\n",
    "        output, time_diff = get_relation_prediction(i, processed_entities)\n",
    "\n",
    "        outputText = output.choices[0].message.content\n",
    "        input_tokens = output.usage.prompt_tokens\n",
    "        output_tokens = output.usage.completion_tokens\n",
    "\n",
    "        # messages.append({\"role\": \"assistant\", \"content\": outputText})\n",
    "\n",
    "        if debug:\n",
    "            print(f\"\\nInput - {text}\")\n",
    "            # print(f\"\\nGT - {data['Triplets'][i]}\")\n",
    "            print(f\"\\noutput - {outputText}\")\n",
    "\n",
    "        output_data.append([doc_key, chunk_idx, outputText, time_diff,\n",
    "                           input_tokens, output_tokens])\n",
    "            \n",
    "        # else:\n",
    "        #     output_data.append([doc_key, chunk_idx, \"No data\", 0,\n",
    "        #                        0, 0])\n",
    "\n",
    "        if i % 10 == 0 and i > 1:\n",
    "\n",
    "            with open(output_filename, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerows(output_data)\n",
    "                \n",
    "        if debug: break\n",
    "        \n",
    "    if debug: break\n",
    "    \n",
    "    with open(output_filename, 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(output_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5370201-260d-41db-a3cb-f95627353b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['400',\n",
       " 0,\n",
       " 'News Online Today | publication date | 2011/05/15\\nABILA | country | Kronos\\nProtectors of Kronos | country | Kronos\\nDRUG RELATED ARRESTS ON THE RISE | publication date | 2011/05/15\\nDRUG RELATED ARRESTS ON THE RISE | publisher | News Online Today\\nProtectors of Kronos | located in the administrative territorial entity | Kronos\\nABILA | located in the administrative territorial entity | Kronos\\nNews Online Today | located in the administrative territorial entity | ABILA\\nNews Online Today | country | Kronos\\nDRUG RELATED ARRESTS ON THE RISE | located in the administrative territorial entity | ABILA\\nDRUG RELATED ARRESTS ON THE RISE | country | Kronos',\n",
       " 6.3870508670806885,\n",
       " 1125,\n",
       " 161]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_data[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c793e651-fb4a-4b0d-a204-900e14736731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_index': 0,\n",
       "  'chunk_text': \"SOURCE: News Online Today\\n\\nTITLE: KRONOS GOVERNMENT PLANS TAX BREAKS TO ENCOURAGE FOREIGN INVESTMENT \\n\\nPUBLISHED: 1992/12/12\\n \\nLOCATION: ABILA, Kronos \\n\\nThe Government of Kronos is currently planning some of the world's most generous tax breaks for gas investments.\\n\\nThe Government of Kronos is pitching the plan as a win-win situation given that the high-income countries will be struggling to discover and exploit ever-dwindling supplies of fossil-fuels and the developing Kronos needs income, infrastructure, and cheap energy.\",\n",
       "  'chunk_tokens': 85}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Documents']['399']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd80df16-ea9d-47b0-b289-17d0da7ea236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb4ecffe-b07a-49f2-8e94-ff7ae15e8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed.remove(('3',0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e758390-92f1-4fb2-b993-b12c27108a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3',\n",
       " 1,\n",
       " 'All News Today; 2012/04/09; ABILA; Kronos; Silvia Marek; Protectors of Kronos')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_key, chunk_index, data_json[3][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa2ed3-500f-4d0c-a492-d8f4400863c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Process Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed57ad1-38ae-4884-aee5-17b105ba2dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data0 = pd.read_csv(\"openai_mc1_entities_Apr13.csv\", header=None)\n",
    "Data0 = Data0.rename(columns={0: 'doc_key', 1: 'chunk_index', 2: 'entities', 3: 'latency',\n",
    "                            4: 'input_tokens',  5: 'output_tokens'})\n",
    "Data0[\"processed_entities\"] = \"\"\n",
    "print(Data0.shape)\n",
    "\n",
    "Data0 = Data0.iloc[9:]\n",
    "Data0 = Data0.reset_index(drop=True)\n",
    "print(Data0.shape)\n",
    "\n",
    "Data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d115137d-0b0e-41b0-a757-dff9e44144de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "for i in range(Data0.shape[0]):\n",
    "    \n",
    "    # if i != 261: # 1, 5, 27\n",
    "    #     continue\n",
    "        \n",
    "    ent = Data0[\"entities\"][i]\n",
    "    ent2 = ent.split(\"; \")\n",
    "    \n",
    "    ent3 = []\n",
    "    for item in ent2:\n",
    "        item = item.strip()\n",
    "        if item and item not in ent3:\n",
    "            ent3.append(item)\n",
    "    ent3 = \"; \".join(ent3)\n",
    "    \n",
    "#     if ent != ent3:\n",
    "\n",
    "#         print(f\"\\n{i}\")\n",
    "#         print(ent)\n",
    "#         print(f\"\\n{ent3}\")\n",
    "#         print(\"*\"*20)\n",
    "    \n",
    "    Data0[\"processed_entities\"][i] = ent3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142611e3-573d-4f54-b96f-e812210f843c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data0.head()\n",
    "Data0.to_csv('openai_mc1_entities_Apr13_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbe4085-690f-4499-9cf1-1d85594f30f5",
   "metadata": {},
   "source": [
    "## Combine results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a77a17-7293-429f-bb63-f737f43f09c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_key</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>triplets</th>\n",
       "      <th>latency</th>\n",
       "      <th>input_tokens</th>\n",
       "      <th>output_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Jerry Sandusky | spouse | Dottie Sandusky\\nMat...</td>\n",
       "      <td>23.787573</td>\n",
       "      <td>1132</td>\n",
       "      <td>788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Jerry Sandusky | spouse | Dottie Sandusky\\nMat...</td>\n",
       "      <td>9.572027</td>\n",
       "      <td>1132</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Jerry Sandusky | spouse | Dottie Sandusky\\nMat...</td>\n",
       "      <td>11.178822</td>\n",
       "      <td>1132</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Jerry Sandusky | spouse | Dottie Sandusky\\nMat...</td>\n",
       "      <td>18.253995</td>\n",
       "      <td>1132</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Jerry Sandusky | spouse | Dottie Sandusky\\nMat...</td>\n",
       "      <td>17.109828</td>\n",
       "      <td>1132</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_key  chunk_index                                           triplets  \\\n",
       "0        0            0  Jerry Sandusky | spouse | Dottie Sandusky\\nMat...   \n",
       "1        0            1  Jerry Sandusky | spouse | Dottie Sandusky\\nMat...   \n",
       "2        0            2  Jerry Sandusky | spouse | Dottie Sandusky\\nMat...   \n",
       "3        0            3  Jerry Sandusky | spouse | Dottie Sandusky\\nMat...   \n",
       "4        0            4  Jerry Sandusky | spouse | Dottie Sandusky\\nMat...   \n",
       "\n",
       "     latency  input_tokens  output_tokens  \n",
       "0  23.787573          1132            788  \n",
       "1   9.572027          1132            309  \n",
       "2  11.178822          1132            294  \n",
       "3  18.253995          1132            557  \n",
       "4  17.109828          1132            412  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "homeFolder = \"/work/pi_dhruveshpate_umass_edu/project_19/aishwarya/696DS-named-entity-extraction-and-linking-for-KG-construction/code/openai\"\n",
    "\n",
    "main_output = 'sdapr25_relations_combined.csv'\n",
    "\n",
    "DataPath0 = os.path.join(homeFolder, \"sdapr25_relations.csv\")\n",
    "DataPath1 = os.path.join(homeFolder, \"sdapr25_relations_2.csv\")\n",
    "DataPath2 = os.path.join(homeFolder, \"sdapr25_relations_3.csv\")\n",
    "DataPath01 = os.path.join(homeFolder, \"sdapr25_relations_v2.csv\")\n",
    "DataPath11 = os.path.join(homeFolder, \"sdapr25_relations_v2_2.csv\")\n",
    "DataPath21 = os.path.join(homeFolder, \"sdapr25_relations_v2_3.csv\")\n",
    "# DataPath3 = os.path.join(homeFolder, \"openai_relations_gt_redocred_dev_v6.csv\")\n",
    "\n",
    "Data0 = pd.read_csv(DataPath0, header=None)\n",
    "Data1 = pd.read_csv(DataPath1, header=None)\n",
    "Data2 = pd.read_csv(DataPath2, header=None)\n",
    "Data01 = pd.read_csv(DataPath01, header=None)\n",
    "Data11 = pd.read_csv(DataPath11, header=None)\n",
    "Data21 = pd.read_csv(DataPath21, header=None)\n",
    "# Data3 = pd.read_csv(DataPath3, header=None)\n",
    "Data = pd.concat([Data0, Data1, Data2, Data01, Data11, Data21], axis=0)\n",
    "\n",
    "Data = Data.rename(columns={0: 'doc_key', 1: 'chunk_index', 2: 'triplets', 3: 'latency',\n",
    "                           4: 'input_tokens',  5: 'output_tokens', 6: 'article_name'})\n",
    "\n",
    "Data.to_csv(main_output, index=False)\n",
    "\n",
    "# print(Data.shape, len(list(set(list(Data[\"original_index\"])))))\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c8c41-e7b8-4702-87e6-f5cda163563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(list(Data[\"original_index\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1500986-eaa1-4e8a-a59d-fef1f4645cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_id = list(set(list(Data[\"original_index\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d86be8-27b1-4b34-9185-57828a9535d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "check_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "109ec93b-d046-4e77-8023-dfc05bb32907",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87480f58-c59a-414a-a179-3203d459c1c1",
   "metadata": {},
   "source": [
    "## Analyse output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94a9e12-ea69-463c-b6e4-56ede1b11b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "homeFolder = \"/work/pi_dhruveshpate_umass_edu/project_19/aishwarya/696DS-named-entity-extraction-and-linking-for-KG-construction/code/openai\"\n",
    "\n",
    "DataPath0 = 'openai_relations_gt_redocred_dev_all.csv'\n",
    "\n",
    "Data0 = pd.read_csv(DataPath0)\n",
    "\n",
    "Data0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c2bbe7-a45e-45bd-a936-c66507ef629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data0['entities'][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7ad0e-06ee-4dfa-92d6-a84899930a9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-hw1]",
   "language": "python",
   "name": "conda-env-.conda-hw1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
