{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbfcb1fb-0616-4788-902b-93ba2e608dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97278c05-a039-48bb-b7ed-e6a49e5869cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>entity types</th>\n",
       "      <th>relationships</th>\n",
       "      <th>synthetic article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62b1e91ce87f1fc6c056ce9172f5f7c66efba907</td>\n",
       "      <td>By . Lydia Warren . Jerry Sandusky's adopted s...</td>\n",
       "      <td>[['Jerry Sandusky', 'Person'], ['Matthew Sandu...</td>\n",
       "      <td>[['Matthew Sandusky', 'gave an interview to', ...</td>\n",
       "      <td>In a revealing and emotional interview with Op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff693482cdd3dfb9e7064f487516b58f20c060ca</td>\n",
       "      <td>By . Jaymi Mccann . PUBLISHED: . 15:44 EST, 14...</td>\n",
       "      <td>[['Jaymi McCann', 'Person'], ['swimmer', 'Pers...</td>\n",
       "      <td>[['emergency services', 'conduct search and re...</td>\n",
       "      <td>In the scenic Brecon Beacons of Mid Wales, a s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e9900c3b37b1ca3c0a62d203670f7e0e5ac5da89</td>\n",
       "      <td>By . Michael Zennie . A sightseer who tried to...</td>\n",
       "      <td>[['Michael Zennie', 'Person'], ['sightseer', '...</td>\n",
       "      <td>[['Grand Prismatic Spring', 'contains', 'bacte...</td>\n",
       "      <td>In the heart of Wyoming lies the Yellowstone N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fe9d8a82cb4122fdd905012becc7418e2d2ff740</td>\n",
       "      <td>Facebook has started collecting information ab...</td>\n",
       "      <td>[['Facebook', 'Organization'], ['users', 'Conc...</td>\n",
       "      <td>[['Facebook', 'collects information from', 'us...</td>\n",
       "      <td>In a bold move that has stirred up the digital...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aceee806bdda590589d85f67401e6a6a2fc46b2f</td>\n",
       "      <td>By . Deborah Arthurs . PUBLISHED: . 08:32 EST,...</td>\n",
       "      <td>[['Duchess of Cambridge', 'Person'], ['Hobbs',...</td>\n",
       "      <td>[['Duchess of Cambridge', 'wore clothing from'...</td>\n",
       "      <td>In a remarkable display of support for the Bri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  62b1e91ce87f1fc6c056ce9172f5f7c66efba907   \n",
       "1  ff693482cdd3dfb9e7064f487516b58f20c060ca   \n",
       "2  e9900c3b37b1ca3c0a62d203670f7e0e5ac5da89   \n",
       "3  fe9d8a82cb4122fdd905012becc7418e2d2ff740   \n",
       "4  aceee806bdda590589d85f67401e6a6a2fc46b2f   \n",
       "\n",
       "                                             article  \\\n",
       "0  By . Lydia Warren . Jerry Sandusky's adopted s...   \n",
       "1  By . Jaymi Mccann . PUBLISHED: . 15:44 EST, 14...   \n",
       "2  By . Michael Zennie . A sightseer who tried to...   \n",
       "3  Facebook has started collecting information ab...   \n",
       "4  By . Deborah Arthurs . PUBLISHED: . 08:32 EST,...   \n",
       "\n",
       "                                        entity types  \\\n",
       "0  [['Jerry Sandusky', 'Person'], ['Matthew Sandu...   \n",
       "1  [['Jaymi McCann', 'Person'], ['swimmer', 'Pers...   \n",
       "2  [['Michael Zennie', 'Person'], ['sightseer', '...   \n",
       "3  [['Facebook', 'Organization'], ['users', 'Conc...   \n",
       "4  [['Duchess of Cambridge', 'Person'], ['Hobbs',...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  [['Matthew Sandusky', 'gave an interview to', ...   \n",
       "1  [['emergency services', 'conduct search and re...   \n",
       "2  [['Grand Prismatic Spring', 'contains', 'bacte...   \n",
       "3  [['Facebook', 'collects information from', 'us...   \n",
       "4  [['Duchess of Cambridge', 'wore clothing from'...   \n",
       "\n",
       "                                   synthetic article  \n",
       "0  In a revealing and emotional interview with Op...  \n",
       "1  In the scenic Brecon Beacons of Mid Wales, a s...  \n",
       "2  In the heart of Wyoming lies the Yellowstone N...  \n",
       "3  In a bold move that has stirred up the digital...  \n",
       "4  In a remarkable display of support for the Bri...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/work/pi_dhruveshpate_umass_edu/project_19/Data/synthetic_data_Apr25\"\n",
    "file = \"news_training.csv\"\n",
    "\n",
    "data = pd.read_csv(os.path.join(data_path, file))\n",
    "data = data[data.id.notnull()].reindex()\n",
    "data.reset_index(inplace=True, drop=True)\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f43aabfc-b75f-4717-9285-1a77a104e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"processed_entities\"] = \"\"\n",
    "data[\"processed_relations\"] = \"\"\n",
    "\n",
    "all_ent_types = set()\n",
    "\n",
    "for i in data.index:\n",
    "    ent_list = []\n",
    "    tmp = eval(data[\"entity types\"][i])\n",
    "    for item in tmp:\n",
    "        ent_list.append(item[0])\n",
    "        all_ent_types.add(item[1])\n",
    "    data[\"processed_entities\"][i] = \"; \".join(ent_list)\n",
    "    \n",
    "    rel_list = []\n",
    "    tmp = eval(data[\"relationships\"][i])\n",
    "    for item in tmp:\n",
    "        rel_list.append(\" | \".join(item))\n",
    "    data[\"processed_relations\"][i] = \"\\n\".join(rel_list)\n",
    "    \n",
    "    # print(type(tmp), rel_list, \"\\n\".join(rel_list))\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b884893e-8f1f-4391-bd73-d5ee6581b93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>article</th>\n",
       "      <th>entity types</th>\n",
       "      <th>relationships</th>\n",
       "      <th>synthetic article</th>\n",
       "      <th>processed_entities</th>\n",
       "      <th>processed_relations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62b1e91ce87f1fc6c056ce9172f5f7c66efba907</td>\n",
       "      <td>By . Lydia Warren . Jerry Sandusky's adopted s...</td>\n",
       "      <td>[['Jerry Sandusky', 'Person'], ['Matthew Sandu...</td>\n",
       "      <td>[['Matthew Sandusky', 'gave an interview to', ...</td>\n",
       "      <td>In a revealing and emotional interview with Op...</td>\n",
       "      <td>Jerry Sandusky; Matthew Sandusky; Oprah Winfre...</td>\n",
       "      <td>Matthew Sandusky | gave an interview to | Opra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff693482cdd3dfb9e7064f487516b58f20c060ca</td>\n",
       "      <td>By . Jaymi Mccann . PUBLISHED: . 15:44 EST, 14...</td>\n",
       "      <td>[['Jaymi McCann', 'Person'], ['swimmer', 'Pers...</td>\n",
       "      <td>[['emergency services', 'conduct search and re...</td>\n",
       "      <td>In the scenic Brecon Beacons of Mid Wales, a s...</td>\n",
       "      <td>Jaymi McCann; swimmer; emergency services; pol...</td>\n",
       "      <td>emergency services | conduct search and rescue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e9900c3b37b1ca3c0a62d203670f7e0e5ac5da89</td>\n",
       "      <td>By . Michael Zennie . A sightseer who tried to...</td>\n",
       "      <td>[['Michael Zennie', 'Person'], ['sightseer', '...</td>\n",
       "      <td>[['Grand Prismatic Spring', 'contains', 'bacte...</td>\n",
       "      <td>In the heart of Wyoming lies the Yellowstone N...</td>\n",
       "      <td>Michael Zennie; sightseer; Yellowstone; Grand ...</td>\n",
       "      <td>Grand Prismatic Spring | contains | bacteria\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fe9d8a82cb4122fdd905012becc7418e2d2ff740</td>\n",
       "      <td>Facebook has started collecting information ab...</td>\n",
       "      <td>[['Facebook', 'Organization'], ['users', 'Conc...</td>\n",
       "      <td>[['Facebook', 'collects information from', 'us...</td>\n",
       "      <td>In a bold move that has stirred up the digital...</td>\n",
       "      <td>Facebook; users; social media site; privacy po...</td>\n",
       "      <td>Facebook | collects information from | users\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aceee806bdda590589d85f67401e6a6a2fc46b2f</td>\n",
       "      <td>By . Deborah Arthurs . PUBLISHED: . 08:32 EST,...</td>\n",
       "      <td>[['Duchess of Cambridge', 'Person'], ['Hobbs',...</td>\n",
       "      <td>[['Duchess of Cambridge', 'wore clothing from'...</td>\n",
       "      <td>In a remarkable display of support for the Bri...</td>\n",
       "      <td>Duchess of Cambridge; Hobbs; Celeste coat; Liv...</td>\n",
       "      <td>Duchess of Cambridge | wore clothing from | Ho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         id  \\\n",
       "0  62b1e91ce87f1fc6c056ce9172f5f7c66efba907   \n",
       "1  ff693482cdd3dfb9e7064f487516b58f20c060ca   \n",
       "2  e9900c3b37b1ca3c0a62d203670f7e0e5ac5da89   \n",
       "3  fe9d8a82cb4122fdd905012becc7418e2d2ff740   \n",
       "4  aceee806bdda590589d85f67401e6a6a2fc46b2f   \n",
       "\n",
       "                                             article  \\\n",
       "0  By . Lydia Warren . Jerry Sandusky's adopted s...   \n",
       "1  By . Jaymi Mccann . PUBLISHED: . 15:44 EST, 14...   \n",
       "2  By . Michael Zennie . A sightseer who tried to...   \n",
       "3  Facebook has started collecting information ab...   \n",
       "4  By . Deborah Arthurs . PUBLISHED: . 08:32 EST,...   \n",
       "\n",
       "                                        entity types  \\\n",
       "0  [['Jerry Sandusky', 'Person'], ['Matthew Sandu...   \n",
       "1  [['Jaymi McCann', 'Person'], ['swimmer', 'Pers...   \n",
       "2  [['Michael Zennie', 'Person'], ['sightseer', '...   \n",
       "3  [['Facebook', 'Organization'], ['users', 'Conc...   \n",
       "4  [['Duchess of Cambridge', 'Person'], ['Hobbs',...   \n",
       "\n",
       "                                       relationships  \\\n",
       "0  [['Matthew Sandusky', 'gave an interview to', ...   \n",
       "1  [['emergency services', 'conduct search and re...   \n",
       "2  [['Grand Prismatic Spring', 'contains', 'bacte...   \n",
       "3  [['Facebook', 'collects information from', 'us...   \n",
       "4  [['Duchess of Cambridge', 'wore clothing from'...   \n",
       "\n",
       "                                   synthetic article  \\\n",
       "0  In a revealing and emotional interview with Op...   \n",
       "1  In the scenic Brecon Beacons of Mid Wales, a s...   \n",
       "2  In the heart of Wyoming lies the Yellowstone N...   \n",
       "3  In a bold move that has stirred up the digital...   \n",
       "4  In a remarkable display of support for the Bri...   \n",
       "\n",
       "                                  processed_entities  \\\n",
       "0  Jerry Sandusky; Matthew Sandusky; Oprah Winfre...   \n",
       "1  Jaymi McCann; swimmer; emergency services; pol...   \n",
       "2  Michael Zennie; sightseer; Yellowstone; Grand ...   \n",
       "3  Facebook; users; social media site; privacy po...   \n",
       "4  Duchess of Cambridge; Hobbs; Celeste coat; Liv...   \n",
       "\n",
       "                                 processed_relations  \n",
       "0  Matthew Sandusky | gave an interview to | Opra...  \n",
       "1  emergency services | conduct search and rescue...  \n",
       "2  Grand Prismatic Spring | contains | bacteria\\n...  \n",
       "3  Facebook | collects information from | users\\n...  \n",
       "4  Duchess of Cambridge | wore clothing from | Ho...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7575ee-c86e-48bb-ae5a-6247b62e8f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"news_training_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c27376d5-78ce-4f6d-a5d1-b6d843cc3aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ent_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "503f8c61-ed00-4c28-a742-01d960c61e08",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Activity',\n",
       " 'Address',\n",
       " 'Adjective',\n",
       " 'Administrative Bodies',\n",
       " 'Administrative Division',\n",
       " 'Age',\n",
       " 'Age Group',\n",
       " 'Aircraft',\n",
       " 'Aircraft Model',\n",
       " 'Alias',\n",
       " 'Anatomical Structure',\n",
       " 'Animal',\n",
       " 'Animal Breed',\n",
       " 'Animal Group',\n",
       " 'Animal Species',\n",
       " 'Artifact',\n",
       " 'Artistic Work',\n",
       " 'Artwork',\n",
       " 'Assessment Tool',\n",
       " 'Award',\n",
       " 'Award Category',\n",
       " 'Bacteria',\n",
       " 'Band',\n",
       " 'Biological Entity',\n",
       " 'Biological Process',\n",
       " 'Biological Substance',\n",
       " 'Biological System',\n",
       " 'Body Part',\n",
       " 'Book',\n",
       " 'Brand',\n",
       " 'Breed',\n",
       " 'Broadcast Program',\n",
       " 'Categories of Funding',\n",
       " 'Category',\n",
       " 'Cause of Death',\n",
       " 'Cell Type',\n",
       " 'Certification',\n",
       " 'Characteristic',\n",
       " 'Chemical',\n",
       " 'Chemical Compound',\n",
       " 'Chemical Element',\n",
       " 'City',\n",
       " 'Clothing',\n",
       " 'Color',\n",
       " 'Commodity',\n",
       " 'Company',\n",
       " 'Concept',\n",
       " 'Condition',\n",
       " 'Consumer Group',\n",
       " 'Continent',\n",
       " 'Country',\n",
       " 'Creative Work',\n",
       " 'CreativeWork',\n",
       " 'Crime',\n",
       " 'Cuisine',\n",
       " 'Culture',\n",
       " 'Currency',\n",
       " 'Date',\n",
       " 'DateTime',\n",
       " 'Day',\n",
       " 'DayOfWeek',\n",
       " 'Deity',\n",
       " 'Demographic',\n",
       " 'Demographic Group',\n",
       " 'Description',\n",
       " 'Diet',\n",
       " 'Digital Asset',\n",
       " 'Dinosaur Category',\n",
       " 'Dinosaur Species',\n",
       " 'Disease',\n",
       " 'Dish',\n",
       " 'Distance',\n",
       " 'Document',\n",
       " 'Drink',\n",
       " 'Economic Concept',\n",
       " 'Economic Indicator',\n",
       " 'Educational Degree',\n",
       " 'Educational Institution',\n",
       " 'Educational Program',\n",
       " 'Emergency Service Number',\n",
       " 'Emotion',\n",
       " 'Ethnic Group',\n",
       " 'Ethnicity',\n",
       " 'Event',\n",
       " 'Evidence',\n",
       " 'Facility',\n",
       " 'Family',\n",
       " 'Family Relation',\n",
       " 'Family Role',\n",
       " 'Fictional Character',\n",
       " 'Fictional Characters',\n",
       " 'Fictional Location',\n",
       " 'Field',\n",
       " 'Field of Study',\n",
       " 'Film',\n",
       " 'Financial',\n",
       " 'Financial Concept',\n",
       " 'Financial Entity',\n",
       " 'Financial Instrument',\n",
       " 'Food',\n",
       " 'Format',\n",
       " 'Frequency',\n",
       " 'Game',\n",
       " 'Geographical Feature',\n",
       " 'Goods',\n",
       " 'Goods/Services',\n",
       " 'Government Body',\n",
       " 'Government Position',\n",
       " 'Group',\n",
       " 'Group of Countries',\n",
       " 'Group of People',\n",
       " 'Habitat',\n",
       " 'Hashtag',\n",
       " 'Historical Event',\n",
       " 'Holiday',\n",
       " 'Hormone',\n",
       " 'Hospital',\n",
       " 'Identifier',\n",
       " 'Industry',\n",
       " 'Infrastructure',\n",
       " 'Initiative',\n",
       " 'Institution',\n",
       " 'Instrument',\n",
       " 'Job Title',\n",
       " 'Judicial Body',\n",
       " 'Landmark',\n",
       " 'Language',\n",
       " 'Law',\n",
       " 'Legal Case',\n",
       " 'Legal Charge',\n",
       " 'Legal Code',\n",
       " 'Legal Concept',\n",
       " 'Legal Document',\n",
       " 'Legal Document Section',\n",
       " 'Legal Entity',\n",
       " 'Legal Institution',\n",
       " 'Legal Process',\n",
       " 'Legal Sentence',\n",
       " 'Legal Status',\n",
       " 'Legislation',\n",
       " 'Length',\n",
       " 'License Plate',\n",
       " 'Literary Work',\n",
       " 'Literature',\n",
       " 'Location',\n",
       " 'Location Feature',\n",
       " 'Location Group',\n",
       " 'Material',\n",
       " 'Materials',\n",
       " 'Measurement',\n",
       " 'Media',\n",
       " 'Media Outlet',\n",
       " 'Medical Concept',\n",
       " 'Medical Condition',\n",
       " 'Medical Procedure',\n",
       " 'Medical Service',\n",
       " 'Medical Test',\n",
       " 'Medical Treatment',\n",
       " 'Medication',\n",
       " 'Medium',\n",
       " 'Military',\n",
       " 'Military Alliance',\n",
       " 'Military Equipment',\n",
       " 'Military Force',\n",
       " 'Military Operation',\n",
       " 'Military Unit',\n",
       " 'Monetary Value',\n",
       " 'Money',\n",
       " 'Movement',\n",
       " 'Movie',\n",
       " 'Music Genre',\n",
       " 'Musical Group',\n",
       " 'Nationality',\n",
       " 'News Website',\n",
       " 'Newspaper',\n",
       " 'Nickname',\n",
       " 'Number',\n",
       " 'Numerical Position',\n",
       " 'Numerical Statistic',\n",
       " 'Numerical Value',\n",
       " 'Object',\n",
       " 'Occupation',\n",
       " 'Operating System',\n",
       " 'Operation',\n",
       " 'Organism',\n",
       " 'Organization',\n",
       " 'Organization Category',\n",
       " 'Organization Type',\n",
       " 'Organizations',\n",
       " 'Other',\n",
       " 'People',\n",
       " 'Perpetrator',\n",
       " 'Person',\n",
       " 'Person Group',\n",
       " 'Person Type',\n",
       " 'Person or Group',\n",
       " 'PersonGroup',\n",
       " 'Persona',\n",
       " 'Personal Status',\n",
       " 'Persons',\n",
       " 'Pet Name',\n",
       " 'Phone Number',\n",
       " 'PhoneNumber',\n",
       " 'Photograph',\n",
       " 'Plant',\n",
       " 'Platform',\n",
       " 'Police Operation',\n",
       " 'Policy',\n",
       " 'Political Affiliation',\n",
       " 'Political Entities',\n",
       " 'Political Entity',\n",
       " 'Political Group',\n",
       " 'Political Party',\n",
       " 'Political Title',\n",
       " 'Population Group',\n",
       " 'Position',\n",
       " 'Procedure',\n",
       " 'Process',\n",
       " 'Product',\n",
       " 'Product Batch',\n",
       " 'Product Category',\n",
       " 'Product Feature',\n",
       " 'Profession',\n",
       " 'Program',\n",
       " 'Project',\n",
       " 'Publication',\n",
       " 'Published Work',\n",
       " 'Qualification',\n",
       " 'Rank',\n",
       " 'Region',\n",
       " 'Religion',\n",
       " 'Religious Group',\n",
       " 'Report',\n",
       " 'Research Method',\n",
       " 'Role',\n",
       " 'Score',\n",
       " 'Sector',\n",
       " 'Sentence',\n",
       " 'Service',\n",
       " 'Service Feature',\n",
       " 'Social Category',\n",
       " 'Social Group',\n",
       " 'Social Media Account',\n",
       " 'Software',\n",
       " 'Song',\n",
       " 'Spacecraft',\n",
       " 'Species',\n",
       " 'Speed',\n",
       " 'Sport',\n",
       " 'Sporting Event',\n",
       " 'Sports Division',\n",
       " 'Sports Event',\n",
       " 'Sports Event Category',\n",
       " 'Sports League',\n",
       " 'Sports Record',\n",
       " 'Sports Team',\n",
       " 'State',\n",
       " 'Statistic',\n",
       " 'Stegosaurus',\n",
       " 'Structure',\n",
       " 'Subject',\n",
       " 'Substance',\n",
       " 'Surface',\n",
       " 'System',\n",
       " 'TV Show',\n",
       " 'Tax',\n",
       " 'Team',\n",
       " 'Technology',\n",
       " 'Television Channel',\n",
       " 'Television Program',\n",
       " 'Television Show',\n",
       " 'Television Show Segment',\n",
       " 'Time',\n",
       " 'Time Duration',\n",
       " 'Time Period',\n",
       " 'TimePeriod',\n",
       " 'Timeframe',\n",
       " 'Timezone',\n",
       " 'Title',\n",
       " 'Town',\n",
       " 'Treatment',\n",
       " 'Treaty',\n",
       " 'URL',\n",
       " 'Unit',\n",
       " 'Unit of Measure',\n",
       " 'Username',\n",
       " 'Vehicle',\n",
       " 'Venue',\n",
       " 'Vessel',\n",
       " 'Video Game',\n",
       " 'Virus',\n",
       " 'Weapon',\n",
       " 'Weather Condition',\n",
       " 'Website',\n",
       " 'Weight',\n",
       " 'Work of Art',\n",
       " 'Year'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_ent_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a487573-78bc-4e11-9e16-36d3bb20f35a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "924"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tmp = {}\n",
    "\n",
    "for i in data.index:\n",
    "    data_tmp[i] = data[\"synthetic article\"][i]\n",
    "    \n",
    "    # print(type(tmp), tmp)\n",
    "    # break\n",
    "    \n",
    "# Convert to JSON format\n",
    "# json_data = json.dumps({\"Documents\": data_tmp}, indent=4)\n",
    "\n",
    "len(data_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6bf53c62-252d-46d3-b7e3-71a290a78eea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_tmp.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d01c5729-d420-466e-b75b-4c3b2ebecdbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'json_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mtype\u001b[39m(\u001b[43mjson_data\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'json_data' is not defined"
     ]
    }
   ],
   "source": [
    "# type(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f656b006-29e7-4ec4-9f04-f520544c8e33",
   "metadata": {},
   "source": [
    "## Chunk dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bcaff7-99a5-4b46-bac3-27cc8007449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain[llm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e2dc66-90da-4600-aeff-ffae65cb5169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade langchain\n",
    "# !pip install -qU langchain-text-splitters\n",
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61539a1b-22a4-404d-a7a7-faaa3e5317d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/amalgonde_umass_edu/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a36ec8f-e3b5-4791-a113-662bd34edaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "from pprint import pprint\n",
    "# data = json_data\n",
    "# pprint(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbacea80-91fc-4b28-a6b9-5e2d076048ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "\n",
    "json_data = {\"Documents\": data_tmp}\n",
    "\n",
    "chunk_size = 1000\n",
    "overlap_ratio = 0.1\n",
    "chunk_overlap = int(overlap_ratio * chunk_size)\n",
    "\n",
    "def split_into_chunks(text):\n",
    "    text_splitter = NLTKTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap, length_function=len)\n",
    "    chunks = text_splitter.split_text(text)\n",
    "    result = []\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        chunk_tokens = len(word_tokenize(chunk))\n",
    "        result.append({\n",
    "            \"chunk_index\": idx,\n",
    "            \"chunk_text\": chunk,\n",
    "            \"chunk_tokens\": chunk_tokens\n",
    "        })\n",
    "    return result\n",
    "\n",
    "def chunk_text_data(data):\n",
    "    chunked_data = {}\n",
    "\n",
    "    # Chunk documents\n",
    "    for doc_index, text in data.get(\"Documents\", {}).items():\n",
    "        # print(text)\n",
    "        chunked_data[doc_index] = split_into_chunks(text)\n",
    "        # break\n",
    "\n",
    "    return chunked_data\n",
    "\n",
    "chunked_json_data = chunk_text_data(json_data)\n",
    "\n",
    "chunked_json_str = json.dumps(chunked_json_data, indent=4)\n",
    "# print(chunked_json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7999dd9-224a-458b-ad42-59ff131cb527",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunked_json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ddc720d-89b6-4710-9c12-8717e22b3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunked_json_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56191c41-c2a5-4ffc-82ca-1defe00bbbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to JSON file is complete.\n"
     ]
    }
   ],
   "source": [
    "with open('SD_Apr25_chunked_data.json', 'w') as json_file:\n",
    "    json_file.write(chunked_json_str)\n",
    "print(\"Writing to JSON file is complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7e4c1ef2-f241-42d5-9969-4ef0cd109a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/pi_dhruveshpate_umass_edu/project_19/aishwarya/696DS-named-entity-extraction-and-linking-for-KG-construction/datasets/synthetic_data_Apr25\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba229782-b885-4c45-a49c-958d19a47509",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-hw1]",
   "language": "python",
   "name": "conda-env-.conda-hw1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
